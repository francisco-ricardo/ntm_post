
@article{brown:1993,
author = {Brown, Peter F. and Pietra, Vincent J. Della and Pietra, Stephen A. Della and Mercer, Robert L.},
title = {The Mathematics of Statistical Machine Translation: Parameter Estimation},
year = {1993},
issue_date = {June 1993},
publisher = {MIT Press},
address = {Cambridge, MA, USA},
volume = {19},
number = {2},
issn = {0891-2017},
abstract = {We describe a series of five statistical models of the translation process and give algorithms for
estimating the parameters of these models given a set of pairs of sentences that are translations of one another.
We define a concept of word-by-word alignment between such pairs of sentences. For any given pair of such sentences
each of our models assigns a probability to each of the possible word-by-word alignments. We give an algorithm for
seeking the most probable of these alignments. Although the algorithm is suboptimal, the alignment thus obtained
accounts well for the word-by-word relationships in the pair of sentences. We have a great deal of data in French
and English from the proceedings of the Canadian Parliament. Accordingly, we have restricted our work to these two
languages; but we feel that because our algorithms have minimal linguistic content they would work well on other
pairs of languages. We also feel, again because of the minimal linguistic content of our algorithms, that it is
reasonable to argue that word-by-word alignments are inherent in any sufficiently large bilingual corpus.},
journal = {Comput. Linguist.},
month = {6},
pages = {263â€“311},
numpages = {49}
}


@article{maruf:2021,
author = {Maruf, Sameen and Saleh, Fahimeh and Haffari, Gholamreza},
title = {A Survey on Document-Level Neural Machine Translation: Methods and Evaluation},
year = {2021},
issue_date = {March 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {54},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3441691},
doi = {10.1145/3441691},
abstract = {Machine translation (MT) is an important task in natural language processing (NLP),
as it automates the translation process and reduces the reliance on human translators.
With the resurgence of neural networks, the translation quality surpasses that of the translations
obtained using statistical techniques for most language-pairs. Up until a few years ago, almost all
of the neural translation models translated sentences independently, without incorporating the wider
document-context and inter-dependencies among the sentences. The aim of this survey article is to
highlight the major works that have been undertaken in the space of document-level machine translation
after the neural revolution, so researchers can recognize the current state and future directions of
this field. We provide an organization of the literature based on novelties in modelling and
architectures as well as training and decoding strategies. In addition, we cover evaluation strategies
that have been introduced to account for the improvements in document MT, including automatic metrics
and discourse-targeted test sets. We conclude by presenting possible avenues for future exploration
in this research field.},
journal = {ACM Comput. Surv.},
month = {3},
articleno = {45},
numpages = {36},
keywords = {Context-aware neural machine translation}
}


@article{goldberg:2016,
  title={A primer on neural network models for natural language processing},
  author={Goldberg, Yoav},
  journal={Journal of Artificial Intelligence Research},
  volume={57},
  pages={345--420},
  year={2016}
}


@article{stahlberg:2020,
  title={Neural machine translation: A review},
  author={Stahlberg, Felix},
  journal={Journal of Artificial Intelligence Research},
  volume={69},
  pages={343--418},
  year={2020}
}

@article{wu:2016,
  title={Google's neural machine translation system: Bridging the gap between human and machine translation},
  author={Wu, Yonghui and Schuster, Mike and Chen, Zhifeng and Le, Quoc V and Norouzi, Mohammad and Macherey, Wolfgang and Krikun, Maxim and Cao, Yuan and Gao, Qin and Macherey, Klaus and others},
  journal={arXiv preprint arXiv:1609.08144},
  year={2016}
}


@article{sutskever:2014,
  title={Sequence to sequence learning with neural networks},
  author={Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}


@article{kalchbrenner:2016,
  title={Neural machine translation in linear time},
  author={Kalchbrenner, Nal and Espeholt, Lasse and Simonyan, Karen and Oord, Aaron van den and Graves, Alex and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1610.10099},
  year={2016}
}


@article{vaswani:2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

